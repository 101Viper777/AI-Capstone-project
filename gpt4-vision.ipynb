{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "to activate env cd to the project folder and run :\n",
    "\n",
    "source env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=1024)\n",
    "image = encode_image(\"q6.jpeg\")\n",
    "\n",
    "\n",
    "# Initialize an empty list to store conversation history\n",
    "conversation_history = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initial message from the AI (setup the scenario for the chatbot)\n",
    "initial_message = AIMessage(\n",
    "    content=\"\"\n",
    ")\n",
    "\n",
    "# Append the initial setup message to the conversation history\n",
    "conversation_history.append(initial_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine which graph correctly represents the function \\( y = f(x) \\) based on the given signs of its first and second derivatives \\( f'(x) \\) and \\( f''(x) \\), we can analyze the information provided in the table and match it with the characteristics shown in the graphs:\n",
      "\n",
      "- At \\( x = -2 \\), \\( f'(x) \\) is positive, which means the function is increasing at this point.\n",
      "- At \\( x = 0 \\), \\( f'(x) \\) is zero, which indicates a critical point (either a local maximum, minimum, or inflection point).\n",
      "- At \\( x = 2 \\), \\( f'(x) \\) is again positive, so the function is increasing at this point.\n",
      "\n",
      "For the second derivative \\( f''(x) \\):\n",
      "\n",
      "- At \\( x = -2 \\), \\( f''(x) \\) is negative, which suggests the function is concave down at this point (like an upside-down bowl).\n",
      "- At \\( x = 0 \\), \\( f''(x) \\) is zero, which could indicate a point of inflection where the concavity changes.\n",
      "- At \\( x = 2 \\), \\( f''(x) \\) is positive, which suggests the function is concave up at this point (like a right-side-up bowl).\n",
      "\n",
      "Now we can evaluate the options:\n",
      "\n",
      "- Graph A shows a decreasing function at \\( x = -2 \\) (which conflicts with \\( f'(x) \\) being positive) and does not show a change in concavity at \\( x = 0 \\).\n",
      "- Graph B shows a decreasing function at \\( x = -2 \\) and \\( x = 2 \\) (which conflicts with \\( f'(x) \\) being positive at both points) and does not show a change in concavity at \\( x = 0 \\).\n",
      "- Graph C shows an increasing function at \\( x = -2 \\), a critical point at \\( x = 0 \\), and an increasing function at \\( x = 2 \\). It also shows concave down (negative \\( f''(x) \\)) before \\( x = 0 \\) and concave up (positive \\( f''(x) \\)) after \\( x = 0 \\). This graph matches the given derivative signs.\n",
      "- Graph D shows a decreasing function at \\( x = -2 \\) and \\( x = 2 \\), which contradicts the positive \\( f'(x) \\) at those points.\n",
      "\n",
      "Therefore, the correct graph that matches the given information is Graph C.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Simulate receiving a message from the human user\n",
    "user_message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Please solve the following question based on the provided image:\"},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{image}\"\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append the user message to the conversation history\n",
    "conversation_history.append(user_message)\n",
    "\n",
    "# Invoke the model with the conversation history\n",
    "response = chain.invoke(conversation_history)\n",
    "\n",
    "# Print the AI response\n",
    "print(response.content)\n",
    "\n",
    "# Append the AI response to the conversation history for future reference\n",
    "conversation_history.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple chat widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Encode an image to base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Initialize your chat model\n",
    "chain = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=1024)\n",
    "# Example image encoding\n",
    "# image = encode_image(\"test.jpeg\")\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Setup the initial message for the chatbot scenario\n",
    "initial_message = AIMessage(\n",
    "    content=\"You will be a tutor for math students and will help them solve the questions. The student will upload the question with the working out and you will be guiding students through problem-solving steps, offering hints instead of direct answers to encourage critical thinking don't make the hints give away the answer.\"\n",
    ")\n",
    "conversation_history.append(initial_message)\n",
    "\n",
    "# Function to update conversation with user input and get response\n",
    "def update_conversation(user_input):\n",
    "    user_message = HumanMessage(content=[{\"type\": \"text\", \"text\": user_input}])\n",
    "    conversation_history.append(user_message)\n",
    "    response = chain.invoke(conversation_history)\n",
    "    conversation_history.append(response)\n",
    "    return response.content\n",
    "\n",
    "# Tkinter GUI setup\n",
    "class ChatbotUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"Chatbot Tutor\")\n",
    "\n",
    "        self.text_widget = tk.Text(master, state='disabled', width=80, height=20)\n",
    "        self.text_widget.pack(padx=5, pady=5)\n",
    "\n",
    "        self.entry_widget = tk.Entry(master, width=80)\n",
    "        self.entry_widget.pack(padx=5, pady=5)\n",
    "        self.entry_widget.bind(\"<Return>\", self.handle_return)\n",
    "\n",
    "    def handle_return(self, event):\n",
    "        user_input = self.entry_widget.get()\n",
    "        self.entry_widget.delete(0, tk.END)\n",
    "        self.update_chat_window(f\"You: {user_input}\\n\")\n",
    "        bot_response = update_conversation(user_input)\n",
    "        self.update_chat_window(f\"Bot: {bot_response}\\n\")\n",
    "\n",
    "    def update_chat_window(self, message):\n",
    "        self.text_widget.configure(state='normal')\n",
    "        self.text_widget.insert(tk.END, message)\n",
    "        self.text_widget.configure(state='disabled')\n",
    "        self.text_widget.see(tk.END)\n",
    "\n",
    "root = tk.Tk()\n",
    "chat_ui = ChatbotUI(root)\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
